% ============================================================================
% Credit Card Default Prediction - LaTeX Paper Template
% Author: [Your Name]
% Course: [Course Name]
% Date: \today
% ============================================================================

\documentclass[12pt,letterpaper]{article}

% ============================================================================
% PACKAGES
% ============================================================================

% Page layout
\usepackage[margin=1in]{geometry}
\usepackage{setspace}

% Fonts and text
\usepackage{times}  % Times New Roman font
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

% Math and symbols
\usepackage{amsmath,amssymb}

% Graphics and figures
\usepackage{graphicx}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}

% Tables
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}

% Colors
\usepackage{xcolor}

% Hyperlinks
\usepackage[hidelinks]{hyperref}

% Bibliography
\usepackage[style=apa,backend=biber]{biblatex}
\addbibresource{references.bib}

% Line spacing (1.5)
\setstretch{1.5}

% Paragraph settings
\setlength{\parindent}{0.5in}
\setlength{\parskip}{0pt}

% ============================================================================
% TITLE PAGE
% ============================================================================

\title{Predicting Loan Default: A Comparative Analysis of Model Performance and Explainability}

\author{
	Hoang To (ht8758) \\
	The University of Texas at Austin \\
	\\
}

\date{\text{December 01, 2025}}

% ============================================================================
% DOCUMENT
% ============================================================================

\begin{document}
	
	\maketitle	

	%\newpage
	
	% ============================================================================
	% ABSTRACT
	% ============================================================================
	
	\begin{abstract}
	
	Credit underwriting is the lifeblood of financial institutions, yet regulatory requirements for model interpretability have constrained the adoption of state-of-the-art machine learning algorithms in credit risk assessment. This study investigates the magnitude of this interpretability-performance tradeoff by comparing four machine learning models (logistic regression, LightGBM, XGBoost, and neural networks) on a dataset of 255,347 loan records from Coursera's Loan Default Prediction Challenge. Model performance was evaluated using ROC-AUC as the primary metric, with SHAP (SHapley Additive exPlanations) employed to assess explainability across architectures. Results indicate that XGBoost achieved the highest predictive performance (ROC-AUC = 0.759), while logistic regression, the most interpretable model, attained a competitive ROC-AUC of 0.753, a performance gap of 0.82\%. Notably, SHAP analysis revealed consistent feature importance rankings across all models.  These findings suggest that the performance cost of regulatory compliance may be smaller than commonly assumed, and that explainable AI techniques can provide consistent interpretations even for complex methods. 
		
	\end{abstract}
	
	\newpage
	
	% ============================================================================
	% 1. INTRODUCTION
	% ============================================================================
	
	\section{Introduction}
	
	% Background and Motivation (2-3 paragraphs)
	Since the dawn of banking, credit has been the core business through which financial institutions grow and compete with one another. The discipline operates at the intersection of risk management and customer access to credit. As a finance professional at a leading lending company, I experience first hands how our capacity to lend ties directly with our ability to underwrite consumer risk appropriately. At the same time, the Equal Credit Opportunity Act (ECOA) mandates that lenders provide specific reasons for adverse credit decisions \parencite{ecoa1974}. Regulatory guidance from the Federal Reserve and Consumer Financial Protection Bureau reinforces these requirements \parencite{federalreserve2019report, cfpb2020acts}. This has created a significant barrier to adopting advanced machine learning models, particularly neural networks, which are often considered ``black boxes'' due to their complex internal mechanisms \parencite{hurley2016credit}. Thus, financial institutions must predict which borrowers are likely to default while simultaneously maintaining transparency in their lending decisions. This dual challenge has intensified with the advancement of machine learning techniques that offer superior predictive accuracy but often lack the interpretability required for regulatory compliance. As a result, many financial institutions continue to rely on logistic regression and tree-based models despite potentially sacrificing predictive performance \parencite{lessmann2015benchmarking, cfpb2020acts}.
	 
	% Research Questions
	This paper aims to understand two fundamental questions: (1) Are neural network based models outperforming more interpretable logistics and tree-based models? and (2) Can we better explain what drive prediction outcomes of more complex neural network based models to sufficiently meet regulatory requirements? Accurate credit worthiness assessments would help both the lenders and borrowers, whereas the former can assign appropriate level of risk to the borrowers and lower the risk of unexpected losses, allowing the latter to borrow more cheaply \parencite{einav2013impact}.  
	
	% Contribution and Paper Structure
	By comparing four distinct machine learning models, ranging from highly interpretable model (logistic regression) to the ``black box'' model (neural networks), and employing SHAP values for explainability analysis, this paper seeks to provide a repeatable framework to quantify the interpretability-performance tradeoff that financial institutions face, providing actionable insights for practitioners navigating the balance between model performance and regulatory compliance.
	
	% ============================================================================
	% 2. LITERATURE REVIEW
	% ============================================================================
	
	\section{Research Background}
	
	%\subsection{Traditional Credit Scoring Methods}
	
	Credit scoring has been a key pillar of lending decisions for decades. Traditional approaches, particularly FICO scores and logistic regression models, have dominated the industry due to their interpretability and regulatory acceptance \parencite{baesens2003benchmarking, lessmann2015benchmarking, brown2012experimental}. These methods rely on a limited set of financial and demographic variables to predict default probability, with coefficients that can be directly interpreted as the marginal effect of each variable.
	
	%\subsection{Machine Learning in Credit Risk Assessment}
	
	Within the last two decades, the application of machine learning to credit risk has improved significantly. Benchmarking studies demonstrated that ensemble methods could outperform traditional logistic regression \parencite{khandani2010consumer} with random forests and gradient boosting emerged as powerful algorithms for credit scoring. \textcite{wang2011comparative} found that ensemble approaches consistently outperformed single classifiers in credit risk assessment. XGBoost, a scalable tree boosting system \parencite{chen2016xgboost}, has become particularly popular due to its performance and built-in handling of missing values. \textcite{xia2017boosted} demonstrated that boosted decision trees with Bayesian optimization could further improve credit scoring performance.
	
	Deep learning applications in credit risk have shown promising results but has faced adoption challenges. \textcite{sirignano2016deep} demonstrated the potential of deep learning for mortgage risk prediction, while \textcite{hamori2018ensemble} compared ensemble learning with deep learning approaches for default risk analysis. \textcite{kvamme2018predicting} applied convolutional neural networks to mortgage default prediction, while \textcite{bellotti2013forecasting} explored dynamic models for credit card default forecasting. However, the ``black box'' nature of neural networks raises concerns about interpretability and regulatory compliance \parencite{hurley2016credit}. This has limited their widespread usage in credit risk assessment despite their predictive power.
	%\subsection{Explainable AI in Financial Services}
	
	The need for model interpretability in regulated industries has driven research in explainable AI. Industry reports from major consulting firms have highlighted the growing importance of explainable AI in financial services \parencite{deloitte2021ai, mckinsey2020future, pwc2021explainable}. FICO, a leading credit scoring company, has published guidance on implementing explainable machine learning for credit risk \parencite{fico2018explainable}. \textcite{lundberg2017unified} introduced SHAP (SHapley Additive exPlanations), a unified framework for interpreting model predictions based on cooperative game theory. This approach assigns each feature an importance value for a particular prediction, providing both local (individual prediction) and global (overall model) explanations. \textcite{lundberg2020local, molnar2020interpretable} extended their work by demonstrating how SHAP values can provide global understanding of tree-based models. \textcite{bussmann2021explainable} specifically examined explainable machine learning in credit risk management, arguing that SHAP and similar techniques could bridge the gap between model performance and regulatory requirements. Prior to SHAP, \textcite{ribeiro2016should} introduced LIME (Local Interpretable Model-agnostic Explanations), which provides local explanations for any classifier. \textcite{barredo2020explainable} provides a taxonomy of explanable AI methods and their applications in responsible AI. In this research, we will use SHAP to gauge the interpretability across machine learning models.

	
	% ============================================================================
	% 3. DATA
	% ==========================================================================
	
	\section{Data}
		
	In aimming to addresses the research questions, this paper utilizes the \href{https://www.coursera.org/projects/data-science-coding-challenge-loan-default-prediction}{Loan Default Prediction dataset from Coursera's Loan Default Prediction Challenge}, which contains borrower information for credit default prediction. The dataset includes 255,347 observations with 16 columns describing a borrower's characteristics such as age, income, credit score, education, etc. that will be used as features (Table \ref{tab:features}). Last but not least, there is a binary target variable indicating default status.
	
	% Add a table of features
	\begin{table}[H]
		\centering
		\caption{Dataset Features}
		\label{tab:features}
		\begin{tabular}{lll}
			\toprule
			\textbf{Feature} & \textbf{Type} & \textbf{Description} \\
			\midrule
			Age & Numerical & Age of the borrower \\
			Income & Numerical & Annual income \\
			LoanAmount & Numerical & Amount of money borrowed \\
			CreditScore & Numerical & Credit score (creditworthiness) \\
			MonthsEmployed & Numerical & Months of employment \\
			NumCreditLines & Numerical & Number of open credit lines \\
			InterestRate & Numerical & Loan interest rate \\
			LoanTerm & Numerical & Loan term in months \\
			DTIRatio & Numerical & Debt-to-Income ratio \\
			Education & Categorical & Highest education level \\
			EmploymentType & Categorical & Employment status \\
			MaritalStatus & Categorical & Marital status \\
			HasMortgage & Categorical & Mortgage status (Yes/No) \\
			HasDependents & Categorical & Has dependents (Yes/No) \\
			LoanPurpose & Categorical & Purpose of the loan \\
			HasCoSigner & Categorical & Co-signer status (Yes/No) \\
			\bottomrule
		\end{tabular}
		
	\end{table}
	\subsection{Exploratory Data Analysis}
	
	Prior to apply any algorithms, we looked through the dataset to have a gasp of the features being leveraged to answer the research questions (Table \ref{tab:summary_stats}). The dataset composed of loans being made to a diverse range of borrowers (income ranges from \$15,000 to \$150,000, loan amount from \$5,000 to \$250,000, etc.). Fortunately, there was no missing-values among the features. 
	
	\begin{table}[htbp]
	\centering
	\caption{Summary Statistics}
	\label{tab:summary_stats}
	\resizebox{\textwidth}{!}{%
	\begin{tabular}{lrrrrrrrrrr}
	\toprule
	& Age & Income & LoanAmount & CreditScore & MonthsEmployed & NumCreditLines & InterestRate & LoanTerm & DTIRatio \\
	\midrule
	mean & 43.50 & 82,499 & 127,579 & 574.26 & 59.54 & 2.50 & 13.49 & 36.03 & 0.50  \\
	std & 14.99 & 38,963 & 70,841 & 158.90 & 34.64 & 1.12 & 6.64 & 16.97 & 0.23  \\
	min & 18.00 & 15,000 & 5,000 & 300.00 & 0.00 & 1.00 & 2.00 & 12.00 & 0.10  \\
	25\% & 31.00 & 48,826 & 66,156 & 437.00 & 30.00 & 2.00 & 7.77 & 24.00 & 0.30  \\
	50\% & 43.00 & 82,466 & 127,556 & 574.00 & 60.00 & 2.00 & 13.46 & 36.00 & 0.50  \\
	75\% & 56.00 & 116,219 & 188,985 & 712.00 & 90.00 & 3.00 & 19.25 & 48.00 & 0.70  \\
	max & 69.00 & 149,999 & 249,999 & 849.00 & 119.00 & 4.00 & 25.00 & 60.00 & 0.90  \\
	\bottomrule
	\end{tabular}%
	}
	\end{table}

	Lastly, the default rate within the dataset is around 11.6\%, which raised a question of imbalanced data, which will be discussed in Section \ref{sec:imbalance}.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\textwidth]{figures/default_distribution.png}
		\caption{Distribution of Default vs Non-Default Cases}
		\label{fig:default_dist}
	\end{figure}
	


	\subsection{Data Preprocessing}\label{sec:preprocessing}
	\subsubsection{Correlated Features}
	To identify multicollinearity among the numerical features, a correlation matrix was computed (Figure \ref{fig:correlation_matrix}). Features with correlation coefficients above 0.8 would be considered highly correlated. In this dataset, we did not see any features with correlation coefficients higher than 0.2, therefore no numerical feature was dropped from the analysis.

	\begin{figure}[H]
		\centering
		\includegraphics[width=0.9\textwidth]{figures/correlated_heatmap.png}
		\caption{Feature Correlation Heatmap}
		\label{fig:correlation_matrix}
	\end{figure}
	
	\subsubsection{Normalization and Encoding}
	Subsequently, the following steps were applied to preprocess the data:
	
	\begin{itemize}
		\item \textbf{Train-Test Split:} The dataset was partitioned into training (80\%) and testing (20\%) subsets using stratified sampling to preserve the class distribution of the target variable (Default) in both sets. This is critical given the class imbalance present in the data (approximately 11.6\% default rate).

		\item \textbf{Categorical Encoding:} One-hot encoding (dummy variable encoding) was applied to all categorical variables: Education (4 categories: High School, Bachelor's, Master's, PhD), EmploymentType (4 categories: Full-time, Part-time, Self-employed, Unemployed), MaritalStatus (3 categories: Single, Married, Divorced), HasMortgage (2 categories: Yes, No), HasDependents (2 categories: Yes, No), LoanPurpose (5 categories: Home, Auto, Education, Business, Other), and HasCoSigner (2 categories: Yes, No). One-hot encoding was chosen over label encoding to avoid introducing ordinal relationships where none exist, which could mislead tree-based and linear models.

		\item \textbf{Feature Scaling/Normalization:} Numerical features (Age, Income, LoanAmount, CreditScore, MonthsEmployed, NumCreditLines, InterestRate, LoanTerm, DTIRatio) were standardized using z-score normalization:
		\begin{equation}
		z = \frac{x - \mu}{\sigma}
		\end{equation}
		where $\mu$ is the feature mean and $\sigma$ is the standard deviation. Standardization ensures all features have mean 0 and standard deviation 1, which is important for gradient-based optimization in logistic regression and neural networks, and improves convergence speed. 
	\end{itemize}
	After preprocessing, the original 16 predictor variables (9 numerical, 7 categorical) were transformed into 24 features: 9 standardized numerical features plus 15 binary indicator variables from one-hot encoding.
	\subsection{Class Imbalance Considerations}\label{sec:imbalance}
	
	With a default rate of 11.6\%, there is an imbalance in the data. Rather than applying resampling techniques like SMOTE \parencite{chawla2002smote}, which can introduce artificial patterns, ROC-AUC was selected as the primary evaluation metric as it is robust to class imbalance and evaluates model performance across all classification thresholds \parencite{fawcett2006introduction}.
	% ============================================================================
	% 4. METHODOLOGY
	% ============================================================================
	
	\section{Methods}
	
	\subsection{Model Selection}
	
	Four machine learning models were selected to represent different levels of interpretability and modeling approaches:
	
	\subsubsection{Highly Interpretable Models}

	\textbf{Logistic Regression:} Selected as the baseline model due to its widespread adoption in the credit industry and regulatory acceptance. Logistic regression models the probability of default using the sigmoid function:
	\begin{equation}
	P(Y=1|X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + ... + \beta_n X_n)}}
	\end{equation}
	where each coefficient $\beta_i$ can be exponentiated to obtain odds ratios, providing direct interpretation: a one-unit increase in feature $X_i$ multiplies the odds of default by $e^{\beta_i}$ \parencite{hosmer2013applied}. This transparency makes logistic regression particularly valuable for regulatory compliance under frameworks such as the Equal Credit Opportunity Act (ECOA) and SR 11-7, which require explainable lending decisions. The model was trained with L2 regularization (C=1.0) and a maximum of 1,000 iterations to ensure convergence.

	\subsubsection{Moderately Interpretable Models}

	\textbf{LightGBM:} A gradient boosting framework developed by Microsoft that uses histogram-based algorithms and leaf-wise tree growth for computational efficiency \parencite{ke2017lightgbm}. Unlike traditional gradient boosting methods that grow trees level-wise, LightGBM grows trees by splitting the leaf with the highest delta loss, often resulting in a deeper, more asymmetric trees that can capture more complex interactions. 

	\noindent\textbf{XGBoost (Extreme Gradient Boosting):} A regularized gradient boosting implementation that has become the de facto standard for tabular data competitions and industry applications. XGBoost minimizes a regularized objective function:
	\begin{equation}
	\mathcal{L}(\phi) = \sum_{i} l(\hat{y}_i, y_i) + \sum_{k} \Omega(f_k)
	\end{equation}
	where $l$ is a differentiable convex loss function and $\Omega(f_k) = \gamma T + \frac{1}{2}\lambda ||w||^2$ penalizes model complexity through the number of leaves $T$ and L2 regularization on leaf weights $w$. This built-in regularization helps prevent overfitting, a common concern with high-dimensional credit data. 


	\subsubsection{Low Interpretability Models}

	\textbf{Neural Network:} A feedforward multilayer perceptron (MLP) represents the ``black box'' end of the interpretability spectrum. The architecture consists of an input layer matching the 24 preprocessed features, followed by three hidden layers with 128, 64, and 32 neurons respectively, each using ReLU activation functions:
	\begin{equation}
	\text{ReLU}(x) = \max(0, x)
	\end{equation}
	Dropout regularization (rate = 0.3) was applied between hidden layers to prevent overfitting, and the output layer uses sigmoid activation for binary classification. The network was trained using the Adam optimizer with binary cross-entropy loss and early stopping monitoring validation loss. 
	\subsection{Evaluation Metrics}
	
	Model performance was assessed using multiple classification metrics:
	
	\begin{itemize}
		\item \textbf{Accuracy:} Overall proportion of correct predictions
		\item \textbf{Precision:} Ability to minimize false positives (incorrectly predicting default)
		\item \textbf{Recall:} Ability to identify actual defaults
		\item \textbf{F1-Score:} Harmonic mean of precision and recall
		\item \textbf{ROC-AUC:} Area under the receiver operating characteristic curve
	\end{itemize}
	
	ROC-AUC was selected as the primary metric because it evaluates model performance across all classification thresholds and, as mentioned, is less sensitive to class imbalance than accuracy \parencite{he2009learning}.
	
	
	% ============================================================================
	% 5. RESULTS
	% ============================================================================
	
	\section{Results}
	
	\subsection{Model Performance}
	
	Table \ref{tab:model_performance} below presents the performance metrics for all four models. As discussed, ROC-AUC is the primary metric used to rank the models' performance. 

	\begin{table}[h!]
		\centering
		\caption{Model Performance Comparison}
		\label{tab:model_performance}
		\begin{tabular}{lccccc}
			\toprule
			\textbf{Model} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{ROC-AUC} \\
			\midrule
			XGBoost & 0.886 & 0.618 & 0.063 & 0.114 & 0.759 \\
			Neural Network & 0.884 & 0.699 & 0.016 & 0.032 & 0.758 \\
			LightGBM & 0.886 & 0.620 & 0.063 & 0.115 & 0.757 \\
			Logistic Regression & 0.885 & 0.608 & 0.034 & 0.064 & 0.753 \\
			\bottomrule
    \end{tabular}
	\end{table}

	
	The XGBoost model demonstrated the best overall performance with a ROC-AUC of 0.7593, closely followed by the Neural Network (0.7586) and LightGBM (0.7580), showing minimal separation among the top three models. The baseline Logistic Regression model achieved a competitive ROC-AUC of 0.7531, indicating the more complex ensemble methods provided only marginal gains in the area under the curve. Regarding the precision versus recall tradeoff, all models exhibited very high precision (XGBoost at 0.6188, Neural Network highest at 0.6993) coupled with extremely low recall (ranging from 0.0169 to 0.0634). This notable pattern confirms the severe class imbalance of the default data and suggests the models are highly selective and accurate when predicting a positive default, but they miss the vast majority of actual positive cases (high number of false negatives), which explains why the F1-Scores remain low across the board. Figure \ref{fig:roc_curves} displays the ROC curves for all five models.
	
	% Add ROC curves figure
	\begin{figure}[H]
		\centering
		\caption{ROC Curves for All Models}
		\includegraphics[width=0.85\textwidth]{figures/roc_curves.png}
		\label{fig:roc_curves}
	\end{figure}
	
	
	
	\subsection{Model Explainability using SHAP}
	
	Shapley values explain how each feature contributes to the prediction by evaluating how various feature value combinations would affect the prediction outcome compared to the average prediction output \parencite{lundberg2017unified}. It would reveal the most important features for default prediction across all models. To ensure a fair comparison of model explainability, SHAP values were calculated for all classifiers using the most appropriate and efficient method for each architecture: LinearExplainer was used for the Logistic Regression model to compute exact SHAP values directly from its coefficients; TreeExplainer was applied to the tree-based models (LightGBM and XGBoost), taking advantage of their underlying structure for efficient computation; and KernelExplainer provided a model-agnostic, sampled approximation of the SHAP values for the Neural Network. This comprehensive SHAP analysis facilitates both global feature importance assessment (determining which features are most impactful overall) to assess the interpretability of complex models.

	The images below (Figure \ref{fig:shap_summary}) show the SHAP summary plots for each model, illustrating the impact of the top 20 features on model output. The color represents the feature value (red = high, blue = low), while the position on the x-axis indicates the SHAP value (positive values increase predicted default risk, negative values decrease it). 

	\noindent The top five most important features across models were:
	\begin{itemize}
		\item \textbf{Age} (The age of the borrower) is the most importance feature across all models. We see that younger borrowers (lower age values) tend to have higher SHAP values, indicating a higher predicted risk of default. This suggests that younger individuals may be perceived as riskier borrowers, possibly due to less established credit histories or financial stability.
		\item \textbf{InterestRate} (The interest rate for the loan) is the second most important feature. Higher interest rates (red points) are associated with higher SHAP values, indicating that loans with higher interest rates contribute to an increased predicted risk of default. This aligns with the intuition that higher borrowing costs may strain a borrower's ability to repay.
		\item \textbf{Income} (The annual income of the borrower) shows that lower income levels (blue points) correspond to higher SHAP values, suggesting that borrowers with lower incomes are more likely to default. This reflects the financial vulnerability of lower-income individuals in meeting debt obligations.
		\item \textbf{MonthsEmployed} (The number of months the borrower has been employed) indicates that borrowers with shorter employment durations (blue points) have higher SHAP values, implying a higher risk of default. This may be due to job instability or lack of steady income.
		\item \textbf{LoanAmount} (The amount of money being borrowed) shows that larger loan amounts (red points) are associated with higher SHAP values, indicating that borrowing larger sums increases the predicted risk of default. This could be due to the increased financial burden associated with repaying larger loans.
	\end{itemize}
	
	% Add SHAP summary plots
	\begin{figure}[H]
		\centering
		\begin{subfigure}[b]{0.49\textwidth}
			\includegraphics[width=\textwidth]{figures/shap_logistic_regression.png}
			\caption{Logistic Regression}
		\end{subfigure}
		\hfill
		\begin{subfigure}[b]{0.49\textwidth}
			\includegraphics[width=\textwidth]{figures/shap_xgboost.png}
			\caption{XGBoost}
		\end{subfigure}
		
		\vspace{1.0cm}

		\begin{subfigure}[b]{0.49\textwidth}
			\includegraphics[width=\textwidth]{figures/shap_lightgbm.png}
			\caption{LightGBM}
		\end{subfigure}
		\hfill
		\begin{subfigure}[b]{0.49\textwidth}
			\includegraphics[width=\textwidth]{figures/shap_neural_network.png}
			\caption{Neural Network  }
		\end{subfigure}
		\caption{SHAP Summary Plots for Tested Models}
		\label{fig:shap_summary}
	\end{figure}
	
	While the top features are rather straightforward. It is the consistency of them showing up across models that shows the promising utility of SHAP in providing sufficient explainability for complex models. Although the magnitude of their SHAP values varied. For instance, Age had a more pronounced impact in the Logistic Regression model compared to the Neural Network, where its influence was more moderate. This variation suggests that while certain features are universally important, their relative contributions can differ based on the model architecture and complexity.
	
	\subsection{Limitations and Future Work}

	Despite the methodology employed, the results of our findings are subject to two primary limitations. Firstly, the study relied on a public dataset comprising approximately \textbf{255,000 observations}, which is relatively small for effectively training and optimizing complex, high-capacity models like Neural Networks, especially given the inherent class imbalance in credit default prediction. This limited data size may have constrained the true predictive potential of the more complex models, leading to the observed close performance clustering near the simpler Logistic Regression baseline. Secondly, while several state-of-the-art models were employed, our neural network architecture and hyperparameter tuning were not exhaustively optimized compared to the state of the art tree-based models being used (LightGBM and XGBoost). The modest performance of the Neural Network (ROC-AUC 0.7586) suggests that with more extensive search (e.g., deeper layers, different activation functions, or longer training epochs), its performance might improve significantly, potentially widening the performance gap between tree-based methods and deep learning. Lastly, we noted that the feature sizes are rather limited (around 20), which may not fully mirror real-world production-scale datasets where there may be hundred's of features being used. In that instance, neural network models could perform better and the SHAP values could start diverging across models. Future research should address these limitations by validating the framework on larger, production-scale datasets and incorporating more advanced and fine-tuned machine learning techniques to ensure the models are fully optimized to their best performance.

	
	% ============================================================================
	% 6. CONCLUSION
	% ============================================================================
	
	\section{Conclusion}

	This study set out to address fundamental questions about the application of machine learning to credit default prediction: which models perform best, is there performance gain being left on the table by financial institutions due to regulatory requirements, and whether explainable AI techniques can be the bridge to understand 'black-box' models better.

	Our analysis revealed several findings, starting with the model performance ranking. The XGBoost model achieved the highest predictive performance with an ROC-AUC of 0.759.  Surprisingly, our neural-network model had an ROC-AUC of 0.758, less than XGBoost and indicates that tree-based models may still provide the best performance compared to more advanced models. Furthermore, SHAP analysis successfully provided interpretable explanations across all models, with a high degree of consistency in the ranking of the most important features (e.g., age, income, interest rate). However, the ultimate sufficiency of SHAP for full regulatory compliance remains context-dependent and requires further industry clarification.

	This research makes several contributions to both academic literature and industry practice. Primarily, it explored the performance sacrifice required for interpretability in this domain by quantifying the minor ROC-AUC difference between complex and simple models. Secondly, the study evaluates SHAP across multiple model types (including Linear, Tree, and Neural Network), assessing its potential to enable the safe deployment of otherwise black-box models in a regulated financial environment.

	For financial institutions navigating the performance-interpretability tradeoff, flexibility in approach is recommended. For a conservative approach, firms should deploy the highly interpretable models, such as Logistic Regression or Decision Trees (XGBoost), in scenarios where regulatory requirements are strict or uncertain. Conversely, an innovative approach involves utilizing more advanced complex models (neural network) coupled with SHAP analysis for generating explanations; this would require a strong partnership with regulators to establish the acceptability of SHAP-based adverse action (rejection) notices. The future of credit scoring lies not in choosing between performance and interpretability, but in developing methods that optimize both simultaneously. As machine learning continues to advance, the credit industry must balance three competing imperatives: maximizing predictive accuracy to manage risk, maintaining transparency to satisfy regulations, and ensuring fairness to serve all consumers equitably. The path forward requires continued collaboration between researchers, practitioners, and regulators to develop credit scoring systems that are simultaneously accurate, interpretable, and fair.
	
	% ============================================================================
	% REFERENCES
	% ============================================================================
	
	\newpage 
	\printbibliography[title=References]
	

	
\end{document}
